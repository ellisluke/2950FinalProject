{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96d7745-77a6-4b59-989f-d8b7e6a3a1eb",
   "metadata": {},
   "source": [
    "# Data Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef47b71f-600b-49b6-aa94-9b484c5470c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8e632-c2f3-4ba4-a10f-036c5f0fe977",
   "metadata": {},
   "source": [
    "#### Import Billboard CSV\n",
    "And then convert the WeekID column to be of the datetime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62515c10-0cb2-4887-8fd4-ef4502a33981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "charts = pd.read_csv(\"Hot Stuff.csv\")\n",
    "charts.WeekID = pd.to_datetime(charts.WeekID, errors='ignore', infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0704c85-484e-439b-8ff5-4e8c3ef70dcc",
   "metadata": {},
   "source": [
    "#### Make New Dataframe Songs\n",
    "This dataframe has no duplicate songs like the original, it just uses the last week the song was on the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d1d048-904c-4f7c-9745-0d0f2dd65477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29389, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = charts\n",
    "songs = songs.sort_values('Peak Position', ascending=True).sort_values('Weeks on Chart', ascending=False).drop_duplicates(['SongID'])\n",
    "songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c632c5-795d-472d-8d33-ba764ea2b858",
   "metadata": {},
   "source": [
    "#### Dropping 3 Columns\n",
    "The url, Instance, and Previous Week Position columns were deemed not useful for the upcoming webscraping. Since I knew it was going to be data intensive, I wanted to reduce the size of the dataframe in any way that I could."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7c4c7e-785b-420a-bca4-d9420ddf4aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29389, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = songs.drop(['url', 'Instance', 'Previous Week Position'], axis=1)\n",
    "songs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825ee01-7580-496e-b263-35262e061aef",
   "metadata": {},
   "source": [
    "#### A String Building Function\n",
    "This function converts the data in the songs dataframe into a url of the format for songlyrics.com. Songlyrics.com redirects close searches to the proper page, but I still tried to get it as close to their usual routing format as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939f42d4-d428-4775-9d53-1a4b0973a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that builds URLs for songlyrics.com\n",
    "def urlBuild(song, artist):\n",
    "    url = \"http://www.songlyrics.com/\"\n",
    "    aChunks = artist.replace(' ', '-')\n",
    "    sChunks = song.split(' ')\n",
    "    # for ch in aChunks:\n",
    "        # url = url + ch\n",
    "        # url = url + '-'\n",
    "    url = url + aChunks\n",
    "    url = url + '/'\n",
    "    for ch in sChunks:\n",
    "        url = url + ch\n",
    "        url = url + '-'\n",
    "    url = url + 'lyrics'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a51b8d7-6117-42fa-bc15-fdb7db18caac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.songlyrics.com/Kendrick-Lamar-&-Travis-Scott/Big-Shot-lyrics'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of urlBuild function\n",
    "urlBuild(\"Big Shot\", \"Kendrick Lamar & Travis Scott\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6a7fb-b596-4a0d-b56e-0aad0a51c084",
   "metadata": {},
   "source": [
    "#### The Web Scraping Function\n",
    "The webGrab function uses BeautifulSoup to get the html from the url built in the last step. Then webGrab finds the proper housing of the lyrics, cleans the text a bit, then returns the final lyrics. webGrab can also return \"error, no lyrics found\" when any error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e115eec7-6e6e-46c5-86b9-d74f1cef9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping function to get and clean lyrics\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "failureStr = \"error, no lyrics found\"\n",
    "def webGrab(url):\n",
    "    html = requests.get(url, allow_redirects=True).text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    try:\n",
    "        lyrics = soup.find(id=\"songLyricsDiv\").text\n",
    "    except:\n",
    "        return failureStr\n",
    "    lyrics = lyrics.replace('\\n', ' ')\n",
    "    lyrics = lyrics.replace(',', '')\n",
    "    lyrics = lyrics.replace('-', ' ')\n",
    "    lyrics = lyrics.replace('!', '')\n",
    "    lyrics = lyrics.replace('(', '')\n",
    "    lyrics = lyrics.replace(')', '')\n",
    "    lyrics = lyrics.replace('?', '')\n",
    "    lyrics = lyrics.replace('/>', '')\n",
    "    lyrics = lyrics.replace('<br', ' ')\n",
    "    lyrics = lyrics.lower()\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14c3bc-6ce7-4a0c-97e6-7fa3804847bd",
   "metadata": {},
   "source": [
    "#### Build the URLs and Prepare for Scraping\n",
    "This quick step just made two new columns for the link to the lyrics and to store the lyrics returned by webGrab. The for loop here uses the urlBuild function from above to build all the strings that the webscraping will search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe9ccd4-d6d0-4976-a238-a29be0a62874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## BUILD URLS\n",
    "\n",
    "songs['lyricLink'] = \"\"\n",
    "songs['lyrics'] = \"\"\n",
    "\n",
    "for index, row in songs.iterrows():\n",
    "    songs.loc[index, 'lyricLink'] = urlBuild(row.Song, row.Performer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b4cda09-0303-4a8f-bfdc-41931d2fa874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekID</th>\n",
       "      <th>Week Position</th>\n",
       "      <th>Song</th>\n",
       "      <th>Performer</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Peak Position</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "      <th>lyricLink</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302681</th>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>49</td>\n",
       "      <td>Radioactive</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>RadioactiveImagine Dragons</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>http://www.songlyrics.com/Imagine-Dragons/Radi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302673</th>\n",
       "      <td>2014-03-22</td>\n",
       "      <td>45</td>\n",
       "      <td>Sail</td>\n",
       "      <td>AWOLNATION</td>\n",
       "      <td>SailAWOLNATION</td>\n",
       "      <td>17</td>\n",
       "      <td>79</td>\n",
       "      <td>http://www.songlyrics.com/AWOLNATION/Sail-lyrics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302665</th>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>23</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Blinding LightsThe Weeknd</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>http://www.songlyrics.com/The-Weeknd/Blinding-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278572</th>\n",
       "      <td>2009-10-10</td>\n",
       "      <td>48</td>\n",
       "      <td>I'm Yours</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>I'm YoursJason Mraz</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>http://www.songlyrics.com/Jason-Mraz/I'm-Yours...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278565</th>\n",
       "      <td>1998-10-10</td>\n",
       "      <td>45</td>\n",
       "      <td>How Do I Live</td>\n",
       "      <td>LeAnn Rimes</td>\n",
       "      <td>How Do I LiveLeAnn Rimes</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>http://www.songlyrics.com/LeAnn-Rimes/How-Do-I...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           WeekID  Week Position             Song        Performer  \\\n",
       "302681 2014-05-10             49      Radioactive  Imagine Dragons   \n",
       "302673 2014-03-22             45             Sail       AWOLNATION   \n",
       "302665 2021-05-29             23  Blinding Lights       The Weeknd   \n",
       "278572 2009-10-10             48        I'm Yours       Jason Mraz   \n",
       "278565 1998-10-10             45    How Do I Live      LeAnn Rimes   \n",
       "\n",
       "                            SongID  Peak Position  Weeks on Chart  \\\n",
       "302681  RadioactiveImagine Dragons              3              87   \n",
       "302673              SailAWOLNATION             17              79   \n",
       "302665   Blinding LightsThe Weeknd              3              76   \n",
       "278572         I'm YoursJason Mraz              6              76   \n",
       "278565    How Do I LiveLeAnn Rimes              2              69   \n",
       "\n",
       "                                                lyricLink lyrics  \n",
       "302681  http://www.songlyrics.com/Imagine-Dragons/Radi...         \n",
       "302673   http://www.songlyrics.com/AWOLNATION/Sail-lyrics         \n",
       "302665  http://www.songlyrics.com/The-Weeknd/Blinding-...         \n",
       "278572  http://www.songlyrics.com/Jason-Mraz/I'm-Yours...         \n",
       "278565  http://www.songlyrics.com/LeAnn-Rimes/How-Do-I...         "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138725b-0f13-473b-856c-799800845c56",
   "metadata": {},
   "source": [
    "#### Web Scraping Operation\n",
    "This is the code chunk that takes a long time (so I did not run it to make this appendix).\n",
    "The for loop iterates over all the songs in the dataset and uses webGrab to attempt to get the lyrics. Since the operation takes so long, I put some effort into tracking progress so I could see if I needed to interrupt it and change things. I only had to make some small changes, and it ended up taking about 5 hours to run to completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd8d8c-4744-4d86-8359-7fe3ee61d825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure number:  27\n",
      "total done:  76\n",
      "progress:  0.0025860015652114736\n",
      "Caught an error\n",
      "failure number:  28\n"
     ]
    }
   ],
   "source": [
    "# For each song, scrape songlyrics.com for the lyrics\n",
    "\n",
    "from IPython.display import clear_output\n",
    "count = 0\n",
    "failCount = 0\n",
    "total = songs.shape[0]\n",
    "redirectE = \"Redirect error\"\n",
    "songs['lyricBool'] = False\n",
    "\n",
    "for index, row in songs.iterrows():\n",
    "    count = count + 1\n",
    "    try: \n",
    "        songs.loc[index, 'lyrics'] = webGrab(songs.loc[index, 'lyricLink'])\n",
    "    except:\n",
    "        songs.loc[index, 'lyricBool'] = False\n",
    "        failCount = failCount + 1\n",
    "        songs.loc[index, 'lyrics'] = redirectE\n",
    "        print(\"Caught an error\")\n",
    "        print(\"failure number: \", failCount)\n",
    "        continue\n",
    "    if failureStr in songs.loc[index, 'lyrics'] or \"sorry we have no\" in songs.loc[index, 'lyrics']:\n",
    "        failCount = failCount + 1\n",
    "        songs.loc[index, 'lyricBool'] = False\n",
    "        clear_output(wait=True)\n",
    "        print(\"failure number: \", failCount)\n",
    "    else:\n",
    "        clear_output(wait=True)\n",
    "        print(\"success\")\n",
    "        songs.loc[index, 'lyricBool'] = True\n",
    "    print(\"total done: \", count)\n",
    "    print(\"progress: \", count / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fc2f4-0094-4a75-bd9f-afc8d14f7548",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For the sake of computing time, I've stopped the scraping at 76 pages scraped.\n",
    "\n",
    "Final success rate:  0.7016911089183028"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1a369-9ca0-4ef3-8d2f-87900452cfc7",
   "metadata": {},
   "source": [
    "#### Eliminate Songs without Lyrics\n",
    "Since I was tracking whether or not lyrics were found in the lyricBool column in the last step, I simply cut down the dataset further to only contain songs for which the web scraping had found lyrics. Then this dataframe is ready for analysis, so it is exported as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "643b8ab2-c85d-423a-a032-e5061a9acd81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lyricBool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ace9b6921626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msongsWithLyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msongs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msongs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlyricBool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lyricBool'"
     ]
    }
   ],
   "source": [
    "songsWithLyrics = songs.loc[songs.lyricBool == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3afb4-f994-49a6-a449-579642bdbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "songsWithLyrics.to_csv(\"songsWithLyrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1627f-b8c4-4910-ae50-66590444205f",
   "metadata": {},
   "source": [
    "#### Counting and Saving the Word Counts\n",
    "The following code blocks iterate over all the song lyrics found and adds/counts them in a dict. The first block here counts duplicates, then saves it as a JSON file in the next block. \n",
    "The third code block is similar to the first, but it puts all the lyrics of each song in a set, then adds/counts them in a dict. This removes duplicate words in the same song. Then this is saved as a different JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00731005-64ea-473f-8b8f-2718d2182eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Count most common words with duplicates\n",
    "songCount = {}\n",
    "\n",
    "for row in songsWithLyrics.lyrics:\n",
    "    temp = row.split(' ')\n",
    "    \n",
    "    for word in temp:\n",
    "        if word not in songCount:\n",
    "            songCount[word] = 1\n",
    "        else:\n",
    "            songCount[word] = songCount[word] + 1\n",
    "\n",
    "sortedCounts = dict(sorted(songCount.items(), key= lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8d056-215c-4f72-a598-93be47042f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"totalCount\", \"w\") as file:\n",
    "    json.dump(sortedCounts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04dfe7-20c1-4eef-babe-bfa806eb2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count most common words with no duplicates\n",
    "songCount2 = {}\n",
    "\n",
    "for row in songsWithLyrics.lyrics:\n",
    "    temp = row.split(' ')\n",
    "    \n",
    "    dupList = list(set(temp))\n",
    "    for word in dupList: \n",
    "        if word not in songCount:\n",
    "            songCount2[word] = 1\n",
    "        else:\n",
    "            songCount2[word] = songCount2[word] + 1\n",
    "\n",
    "sortedCountsNoDupes = dict(sorted(songCount2.items(), key= lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708151df-764f-4cd9-94ec-a9850a88f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"totalCountNoDupes\", \"w\") as file:\n",
    "    json.dump(sortedCountsNoDupes, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
